{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/akcgjc007/51b0693b8015ecdc139f1c2b3ceb82ea/copy-of-tensorflow-on-chars74k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "eBaKsoPeoykt"
   },
   "outputs": [],
   "source": [
    "# Developer docs\n",
    "# https://www.tensorflow.org/tutorials/keras/classification\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "# Importing modules\n",
    "from os import listdir, system\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2 as cv2\n",
    "import imutils\n",
    "import imageio\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "#from skimage.filters import threshold_otsu\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# Downloading dataset from: http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
    "# You can comment this after running once.\n",
    "# !wget http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
    "# !tar -xvzf ./EnglishImg.tgz\n",
    "# !git clone https://github.com/captcha-breakers/ubiquitous-pancake.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IIDQCtPpAxe",
    "outputId": "b4e51a26-7c79-43d9-f497-7c018c14171b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample011', 'Sample012', 'Sample013', 'Sample014', 'Sample015', 'Sample016', 'Sample017', 'Sample018', 'Sample019', 'Sample020', 'Sample021', 'Sample022', 'Sample023', 'Sample024', 'Sample025', 'Sample026', 'Sample027', 'Sample028', 'Sample029', 'Sample030', 'Sample031', 'Sample032', 'Sample033', 'Sample034', 'Sample035', 'Sample036']\n"
     ]
    }
   ],
   "source": [
    "# Setting up folders\n",
    "base_dir = \"./English/Img/GoodImg/Bmp/\"\n",
    "folders = listdir(base_dir)\n",
    "folders.sort()\n",
    "folders = folders[10:36]\n",
    "print(folders)\n",
    "\n",
    "# Setting image_size\n",
    "image_size = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnjsqbFbpFOQ",
    "outputId": "2b963fb0-ddc0-40e4-d458-e612624080eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  5202\n"
     ]
    }
   ],
   "source": [
    "# Collecting images from folders\n",
    "data = []\n",
    "total_images = 0\n",
    "for i in folders:\n",
    "    all_images = listdir(base_dir+i)\n",
    "    total_images+=len(all_images)\n",
    "    currentlabel = int(i[6:])-11\n",
    "\n",
    "    for name in all_images:\n",
    "        image = cv2.imread(base_dir+i+\"/\"+name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, image_size)\n",
    "\n",
    "        # Filtering\n",
    "        image = cv2.GaussianBlur(image,(5,5),0)\n",
    "        image = cv2.Laplacian(image,cv2.CV_64F)\n",
    "        image = cv2.GaussianBlur(image,(5,5),0)\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        image = cv2.filter2D(image,-1,kernel)\n",
    "        # image = cv2.medianBlur(image,5)\n",
    "        # image = cv2.dilate(image,kernel,iterations = 1)\n",
    "        # image = cv2.erode(image,kernel,iterations = 1)\n",
    "        # image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "        # image = cv2.filter2D(image,-1,kernel)\n",
    "        # image = cv2.blur(image,(5,5))\n",
    "\n",
    "        data.append((image/255, currentlabel))\n",
    "print(\"Total images: \", total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "UpjV_ma4613F",
    "outputId": "911b37cb-eabc-4ec4-b895-2e4470aea1a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f374b741b80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing images\n",
    "imshow(data[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kBEvr3VRpKLz"
   },
   "outputs": [],
   "source": [
    "# Shuffling data & making train/test\n",
    "np.random.shuffle(data)\n",
    "n = len(data)\n",
    "p = int(80*n/100)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i in range(n):\n",
    "    if i<p:\n",
    "        train_images.append(data[i][0])\n",
    "        train_labels.append(data[i][1])\n",
    "    else:\n",
    "        test_images.append(data[i][0])\n",
    "        test_labels.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Yws9xKLpNHf",
    "outputId": "b2846e52-671f-4af1-c81a-2403996f574d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 2.3813 - accuracy: 0.3500\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.8710 - accuracy: 0.7510\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.5833 - accuracy: 0.8347\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.4285 - accuracy: 0.8803\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.9161\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.2053 - accuracy: 0.9442\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.2942 - accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1555 - accuracy: 0.9584\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1401 - accuracy: 0.9545\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1532 - accuracy: 0.9566\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.0738 - accuracy: 0.9816\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1042 - accuracy: 0.9695\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1408 - accuracy: 0.9634\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.0553 - accuracy: 0.9853\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.0819 - accuracy: 0.9772\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.2897 - accuracy: 0.9199\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9811\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.0259 - accuracy: 0.9950\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.0781 - accuracy: 0.9839\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3748776880>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the model and training it\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=image_size),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(26)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(np.array(train_images), np.array(train_labels), epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db79yJnOzy7g",
    "outputId": "598492f9-a611-4338-d5e8-33599d0e108b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  83.28530259365995\n"
     ]
    }
   ],
   "source": [
    "system(\"mkdir -p models\")\n",
    "# model.save('./models/my_model_84.h5')\n",
    "\n",
    "# Predicting on test images\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(np.array(test_images))\n",
    "\n",
    "p=0\n",
    "for i in range(len(test_images)):\n",
    "  if np.argmax(predictions[i]) == test_labels[i]:\n",
    "    p+=1\n",
    "\n",
    "print(\"Test accuracy: \", 100*p/len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcEypgpaawjr",
    "outputId": "457c04b4-7a61-4861-cd01-1f62691c302f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive predictions:  481\n",
      "Negetive predictions:  85\n",
      "Accuracy:  84.98233215547704\n"
     ]
    }
   ],
   "source": [
    "fil_dir = \"./ubiquitous-pancake/captchas/\"\n",
    "ct = 0\n",
    "p = 0\n",
    "n = 0\n",
    "for fil in listdir(fil_dir)[:100]:\n",
    "  image = cv2.imread(fil_dir + fil)\n",
    "\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "  cnts, new = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] \n",
    "  new_image = cv2.drawContours(image,cnts,-1,(0,255,0),1)\n",
    "\n",
    "  mea_image = []\n",
    "  mea_image.append(thresh[:, :])\n",
    "  captcha = np.invert(mea_image[0])\n",
    "  labelled_captcha = measure.label(captcha)\n",
    "\n",
    "  character_dimensions = (0.20*captcha.shape[0], 0.8*captcha.shape[0], 0.03*captcha.shape[1], 0.25*captcha.shape[1])\n",
    "  min_height, max_height, min_width, max_width = character_dimensions\n",
    "\n",
    "  characters = []\n",
    "  charactersx = []\n",
    "  counter=0\n",
    "  column_list = []\n",
    "  row_list = []\n",
    "  i = 0\n",
    "  for regions in regionprops(labelled_captcha):\n",
    "      y0, x0, y1, x1 = regions.bbox\n",
    "      region_height = y1 - y0\n",
    "      region_width = x1 - x0\n",
    "\n",
    "      if region_height > min_height and region_height < max_height and region_width > min_width and region_width < max_width:\n",
    "          roi = captcha[y0:y1, x0:x1]\n",
    "          resized_char = cv2.copyMakeBorder(roi, 5, 5, 5, 5, cv2.BORDER_CONSTANT)\n",
    "          resized_char = resize(roi, (20, 20))\n",
    "          column_list.append(x0)\n",
    "          characters.append(resized_char)\n",
    "  counter = 0\n",
    "\n",
    "  classification_result = []\n",
    "  for each_character in characters:\n",
    "      x_p,y_p = 2,2\n",
    "      each_character = cv2.copyMakeBorder(each_character, x_p, x_p, y_p, y_p, cv2.BORDER_CONSTANT)\n",
    "      each_character = cv2.GaussianBlur(each_character,(5,5),0)\n",
    "      each_character = cv2.Laplacian(each_character,cv2.CV_64F)\n",
    "      each_character = cv2.GaussianBlur(each_character,(5,5),0)\n",
    "      \n",
    "      each_character = cv2.resize(each_character,(20,20))\n",
    "\n",
    "      kernel = np.ones((3, 3), np.uint8)\n",
    "      each_character = cv2.filter2D(each_character,-1,kernel)\n",
    "      cv2.waitKey(1000)\n",
    "      each_character = each_character.reshape(1, -1);\n",
    "      result,  = probability_model.predict([each_character])\n",
    "      label = ord(fil[counter]) - 65\n",
    "      if(label == np.argmax(result)):\n",
    "        p += 1\n",
    "      else:\n",
    "        n+=1\n",
    "      classification_result.append(result)\n",
    "      counter += 1\n",
    "  \n",
    "  ct += 1\n",
    "  print(\"Current file: \", ct)\n",
    "  clear_output(wait=True)\n",
    "  \n",
    "print(\"Postive predictions: \", p)\n",
    "print(\"Negetive predictions: \", n)\n",
    "print(\"Accuracy: \", p*100/(p+n))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Captcha-using-tensorflow-on-chars74K.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
