{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eBaKsoPeoykt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset-training-uppercase-1'...\n",
      "remote: Enumerating objects: 23974, done.\u001b[K\n",
      "remote: Counting objects: 100% (23974/23974), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23974/23974), done.\u001b[K\n",
      "remote: Total 23974 (delta 0), reused 23974 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (23974/23974), 16.02 MiB | 20.71 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# Developer docs\n",
    "# https://www.tensorflow.org/tutorials/keras/classification\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "# Importing modules\n",
    "from os import listdir, system\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import cv2 as cv2\n",
    "import imutils\n",
    "import imageio\n",
    "import pickle\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.io import imread\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# Downloading dataset from: http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
    "# You can comment this after running once.\n",
    "\n",
    "### CHARS74K DATASET FOR TRAINING\n",
    "# !wget http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
    "# !tar -xvzf ./EnglishImg.tgz && rm -rf EnglishImg.tgz\n",
    "# !git clone https://github.com/captcha-breakers/dataset-training-uppercase-1.git\n",
    "\n",
    "# CAPTCHA DATA: DOWNLOAD ANYONE & APPROPRIATELY CONFIGURE THE PATH\n",
    "# !git clone https://github.com/captcha-breakers/dataset-simple-uppercase.git\n",
    "# !git clone https://github.com/rdmpage/solving-captchas-code-examples.git\n",
    "# !git clone https://github.com/captcha-breakers/dataset-pycaptcha-uppercase.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IIDQCtPpAxe",
    "outputId": "3a83fcfd-5935-4f9b-87e2-a5a1660c9103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample1', 'Sample10', 'Sample11', 'Sample12', 'Sample13', 'Sample14', 'Sample15', 'Sample16', 'Sample17', 'Sample18', 'Sample19', 'Sample2', 'Sample20', 'Sample21', 'Sample22', 'Sample23', 'Sample24', 'Sample25', 'Sample26', 'Sample27', 'Sample28', 'Sample29', 'Sample3', 'Sample30', 'Sample31', 'Sample32', 'Sample33', 'Sample34', 'Sample35', 'Sample36', 'Sample4', 'Sample5', 'Sample6', 'Sample7', 'Sample8', 'Sample9']\n"
     ]
    }
   ],
   "source": [
    "# Setting up folders\n",
    "base_dir = \"./dataset-training-uppercase-1/data/\"\n",
    "folders = listdir(base_dir)\n",
    "folders.sort()\n",
    "folders = folders[:36]\n",
    "print(folders)\n",
    "\n",
    "# Setting image_size\n",
    "image_size = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnjsqbFbpFOQ",
    "outputId": "6e5d4a9f-54f2-48a4-cfe2-453434596964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images for 0 : 1000\n",
      "Images for 9 : 1000\n",
      "Images for A : 1000\n",
      "Images for B : 1000\n",
      "Images for C : 1000\n",
      "Images for D : 1000\n",
      "Images for E : 1000\n",
      "Images for F : 1000\n",
      "Images for G : 1000\n",
      "Images for H : 1000\n",
      "Images for I : 1000\n",
      "Images for 1 : 1000\n",
      "Images for J : 1000\n",
      "Images for K : 1000\n",
      "Images for L : 1000\n",
      "Images for M : 1000\n",
      "Images for N : 1000\n",
      "Images for O : 1000\n",
      "Images for P : 1000\n",
      "Images for Q : 1000\n",
      "Images for R : 1000\n",
      "Images for S : 1000\n",
      "Images for 2 : 1000\n",
      "Images for T : 1000\n",
      "Images for U : 1000\n",
      "Images for V : 1000\n",
      "Images for W : 1000\n",
      "Images for X : 1000\n",
      "Images for Y : 1000\n",
      "Images for Z : 1000\n",
      "Images for 3 : 1000\n",
      "Images for 4 : 1000\n",
      "Images for 5 : 1000\n",
      "Images for 6 : 1000\n",
      "Images for 7 : 1000\n",
      "Images for 8 : 1000\n",
      "Total images:  36000\n"
     ]
    }
   ],
   "source": [
    "# Collecting images from folders\n",
    "data = []\n",
    "total_images = 0\n",
    "for i in folders:\n",
    "    all_images = listdir(base_dir+i)[:1000]\n",
    "    total_images+=len(all_images)\n",
    "    currentlabel = int(i[6:])-1\n",
    "\n",
    "    for name in all_images:\n",
    "        image = cv2.imread(base_dir+i+\"/\"+name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, image_size)\n",
    "\n",
    "        # Filtering\n",
    "        # image = cv2.GaussianBlur(image,(5,5),0)\n",
    "        # image = cv2.Laplacian(image,cv2.CV_64F)\n",
    "        # image = cv2.GaussianBlur(image,(5,5),0)\n",
    "        # kernel = np.ones((3, 3), np.uint8)\n",
    "        # image = cv2.filter2D(image,-1,kernel)\n",
    "        \n",
    "        data.append((image/255, currentlabel))\n",
    "    \n",
    "    if int(i[6:])<=10:\n",
    "      print(\"Images for\", currentlabel,\":\",  len(all_images))\n",
    "    else:\n",
    "      print(\"Images for\", chr(65-11+currentlabel+1),\":\",  len(all_images))\n",
    "print(\"Total images: \", total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kBEvr3VRpKLz"
   },
   "outputs": [],
   "source": [
    "# Shuffling data & making train/test\n",
    "np.random.shuffle(data)\n",
    "n = len(data)\n",
    "p = int(80*n/100)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for i in range(n):\n",
    "    if i<p:\n",
    "        train_images.append(data[i][0])\n",
    "        train_labels.append(data[i][1])\n",
    "    else:\n",
    "        test_images.append(data[i][0])\n",
    "        test_labels.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "OuF0sxtOMEwn",
    "outputId": "f039be59-dc79-402e-8b49-f9d6ab4d19bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "9\n",
      "27\n",
      "27\n",
      "15\n",
      "21\n",
      "0\n",
      "30\n",
      "23\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing Training data\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(10):\n",
    "  fig.add_subplot(2, 5, i+1)\n",
    "  print(data[i][1])\n",
    "  imshow(data[i][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Yws9xKLpNHf",
    "outputId": "048a15e2-a5f5-4e44-eea0-a7e8d58a2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "288/288 [==============================] - 3s 8ms/step - loss: 0.5020 - accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "288/288 [==============================] - 2s 9ms/step - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 5/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 1.5444e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 3.2826e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 1.2617e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 6.4742e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 3.7865e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 2.1570e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8d83d6580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the model and training it\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=image_size),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(36)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    np.array(train_images), \n",
    "    np.array(train_labels), \n",
    "    epochs=10,\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db79yJnOzy7g",
    "outputId": "e1d2fe5b-2c4b-434c-c467-1ea013ff90e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "system(\"mkdir -p models\")\n",
    "# model.save('./models/my_model_84.h5')\n",
    "\n",
    "# Predicting on test images\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(np.array(test_images))\n",
    "\n",
    "p=0\n",
    "for i in range(len(test_images)):\n",
    "  if np.argmax(predictions[i]) == test_labels[i]:\n",
    "    p+=1\n",
    "\n",
    "print(\"Test accuracy: \", 100*p/len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "DcEypgpaawjr",
    "outputId": "d2ef12c0-452c-4c77-cd0b-69790c6d6511"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Char</th>\n",
       "      <td>49044</td>\n",
       "      <td>7860</td>\n",
       "      <td>86.187263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Captcha</th>\n",
       "      <td>6554</td>\n",
       "      <td>3446</td>\n",
       "      <td>65.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file:  10000\n",
      "FXYQIR : FXYQR\n"
     ]
    }
   ],
   "source": [
    "fil_dir = \"./dataset-simple-uppercase/data/\"\n",
    "total = 0\n",
    "char_p = 0\n",
    "char_n = 0\n",
    "cap_p = 0\n",
    "cap_n = 0\n",
    "\n",
    "for fil in listdir(fil_dir):\n",
    "  image = cv2.imread(fil_dir + fil)\n",
    "  # imshow(image), plt.show()\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "  cnts, new = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] \n",
    "  captcha = np.invert(thresh)\n",
    "  labelled_captcha = measure.label(captcha)\n",
    "\n",
    "  character_dimensions = (\n",
    "      0.25*captcha.shape[0], \n",
    "      0.95*captcha.shape[0], \n",
    "      0.05*captcha.shape[1], \n",
    "      0.3*captcha.shape[1]\n",
    "  )\n",
    "  min_height, max_height, min_width, max_width = character_dimensions\n",
    "\n",
    "  characters = []\n",
    "  charactersx = []\n",
    "  counter=0\n",
    "  column_list = []\n",
    "  row_list = []\n",
    "  d = []\n",
    "  for regions in regionprops(labelled_captcha):\n",
    "      y0, x0, y1, x1 = regions.bbox\n",
    "      region_height = y1 - y0\n",
    "      region_width = x1 - x0\n",
    "\n",
    "      if region_height > min_height and region_height < max_height and region_width > min_width and region_width < max_width:\n",
    "          roi = captcha[y0:y1, x0:x1]\n",
    "          resized_char = cv2.copyMakeBorder(roi, 10, 10, 10, 10, cv2.BORDER_CONSTANT)\n",
    "          resized_char = resize(roi, image_size)\n",
    "          column_list.append(x0)\n",
    "          d.append([x0, resized_char])\n",
    "  d = sorted(d)\n",
    "  predicted_captcha = \"\"  \n",
    "  ind=0\n",
    "  for _,each_character in d:\n",
    "      x_p,y_p = 3,3\n",
    "      each_character = cv2.copyMakeBorder(each_character, x_p, x_p, y_p, y_p, cv2.BORDER_CONSTANT)\n",
    "      each_character = cv2.resize(each_character,image_size)\n",
    "      \n",
    "      # imshow(each_character), plt.show()\n",
    "      each_character = each_character.reshape(1, -1)\n",
    "    \n",
    "      result, = probability_model.predict([each_character])\n",
    "      r = np.argmax(result)\n",
    "      \n",
    "      if r<10:\n",
    "        # print(chr(48+r))\n",
    "        predicted_captcha+=chr(48+r)\n",
    "        if fil[ind] == chr(48+r):char_p += 1\n",
    "        else:char_n += 1\n",
    "      else:\n",
    "        # print(chr(55+r))\n",
    "        predicted_captcha+=chr(65-10+r)\n",
    "        if fil[ind] == chr(65-10+r):char_p += 1\n",
    "        else:char_n += 1\n",
    "      ind += 1\n",
    "  \n",
    "  if predicted_captcha == fil[:6]: cap_p+=1\n",
    "  else:cap_n+=1\n",
    "\n",
    "  # Statistics\n",
    "  stats = pd.DataFrame(\n",
    "    [\n",
    "        [char_p, char_n, 100*char_p/(char_p+char_n)], \n",
    "        [cap_p, cap_n, 100*cap_p/(cap_p+cap_n)]\n",
    "    ], \n",
    "    index=[\"Char\", \"Captcha\"],\n",
    "    columns=[\"Pos\", \"Neg\", \"Acc\"]\n",
    "  )\n",
    "  total+=1\n",
    "  clear_output(wait=True)\n",
    "  display(HTML(stats.to_html()))\n",
    "  print(\"Current file: \", total)\n",
    "  print(fil[:6], \":\", predicted_captcha)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Captcha-using-tensorflow-on-chars74K.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
