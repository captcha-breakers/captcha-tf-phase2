{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Tensorflow-on-chars74K.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBaKsoPeoykt"
      },
      "source": [
        "# Developer docs\n",
        "# https://www.tensorflow.org/tutorials/keras/classification\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "\n",
        "# Importing modules\n",
        "from os import listdir, system\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import cv2 as cv2\n",
        "import imutils\n",
        "import imageio\n",
        "import pickle\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import tensorflow as tf\n",
        "from skimage.io import imread\n",
        "from skimage import measure\n",
        "from skimage.measure import regionprops\n",
        "from skimage.transform import resize\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "# Downloading dataset from: http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
        "# You can comment this after running once.\n",
        "\n",
        "### CHARS74K DATASET FOR TRAINING\n",
        "# !wget http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
        "# !tar -xvzf ./EnglishImg.tgz && rm -rf EnglishImg.tgz\n",
        "# !git clone https://github.com/captcha-breakers/D-training-segmentation.git\n",
        "\n",
        "# CAPTCHA DATA: DOWNLOAD ANYONE & APPROPRIATELY CONFIGURE THE PATH\n",
        "# !git clone https://github.com/captcha-breakers/dataset-simple-uppercase.git\n",
        "# !git clone https://github.com/rdmpage/solving-captchas-code-examples.git\n",
        "# !git clone https://github.com/captcha-breakers/dataset-pycaptcha-uppercase.git\n",
        "# !git clone https://github.com/captcha-breakers/D-training-color-noise-trans.git\n",
        "# !git clone https://github.com/captcha-breakers/D-captchas-simple-salt-n-pepper.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xHqgpeRwqlZ"
      },
      "source": [
        "# import keras\n",
        "# from keras.models import Sequential, Model\n",
        "# from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "# from keras.layers import Conv2D, MaxPooling2D, Input\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Reshape\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IIDQCtPpAxe",
        "outputId": "7846d1b0-f779-45d8-ebf9-e695d0232991"
      },
      "source": [
        "# Setting up folders\n",
        "base_dir = \"./D-training-color-noise-trans/data/\"\n",
        "folders = listdir(base_dir)\n",
        "folders.sort()\n",
        "folders = folders[10:36]\n",
        "print(folders)\n",
        "\n",
        "# Setting image_size\n",
        "image_size = (32, 32)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sample011', 'Sample012', 'Sample013', 'Sample014', 'Sample015', 'Sample016', 'Sample017', 'Sample018', 'Sample019', 'Sample020', 'Sample021', 'Sample022', 'Sample023', 'Sample024', 'Sample025', 'Sample026', 'Sample027', 'Sample028', 'Sample029', 'Sample030', 'Sample031', 'Sample032', 'Sample033', 'Sample034', 'Sample035', 'Sample036']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnjsqbFbpFOQ",
        "outputId": "c242831d-672b-4db4-bb79-5e8ef3bec0d9"
      },
      "source": [
        "# Collecting images from folders\n",
        "data = []\n",
        "total_images = 0\n",
        "for i in folders:\n",
        "    all_images = listdir(base_dir+i)\n",
        "    total_images+=len(all_images)\n",
        "    currentlabel = int(i[6:])-11\n",
        "\n",
        "    for name in all_images:\n",
        "        image = cv2.imread(base_dir+i+\"/\"+name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = cv2.resize(image, image_size)\n",
        "\n",
        "        # Filtering\n",
        "        image = cv2.GaussianBlur(image,(5,5),0)\n",
        "        image = cv2.Laplacian(image,cv2.CV_64F)\n",
        "        image = cv2.GaussianBlur(image,(5,5),0)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        image = cv2.filter2D(image,-1,kernel)\n",
        "        # image = cv2.medianBlur(image,5)\n",
        "        # image = cv2.dilate(image,kernel,iterations = 1)\n",
        "        # image = cv2.erode(image,kernel,iterations = 1)\n",
        "        # image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "        # image = cv2.filter2D(image,-1,kernel)\n",
        "        # image = cv2.blur(image,(5,5))\n",
        "        image = image.reshape(32, 32, 1)\n",
        "\n",
        "\n",
        "        data.append((image/255, currentlabel))\n",
        "print(\"Total images: \", total_images)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images:  26000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpjV_ma4613F"
      },
      "source": [
        "# # Visualizing images\n",
        "# imshow(data[6][0])#, plt.show()\n",
        "# imshow(data[5][0]), plt.show()\n",
        "# imshow(data[7][0]), plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBEvr3VRpKLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe45ac0-e839-4a8e-f980-acb7c88f4503"
      },
      "source": [
        "# Shuffling data & making train/test\n",
        "np.random.shuffle(data)\n",
        "n = len(data)\n",
        "p = int(80*n/100)\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(n):\n",
        "    if i<p:\n",
        "        train_images.append(data[i][0])\n",
        "        train_labels.append(data[i][1])\n",
        "    else:\n",
        "        test_images.append(data[i][0])\n",
        "        test_labels.append(data[i][1])\n",
        "# train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "# print(train_images)\n",
        "#print(train_labels)\n",
        "print(type(train_images))\n",
        "# image_size =  image_size + (1,)\n",
        "# # image_size.append(3) \n",
        "# # s = set(image_size)\n",
        "\n",
        "\n",
        "print(image_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "(32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACpgLG7g01F5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86708ea0-c333-4e3b-f530-087bead386a8"
      },
      "source": [
        "# train_images = train_images.reshape(list(train_images.shape) + [1])\n",
        "print(np.array(train_labels).shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMib_BgXEgpT"
      },
      "source": [
        "# del model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yws9xKLpNHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d297bbe0-a023-4d2a-c5fb-f7343b04ab4c"
      },
      "source": [
        "# Making the model and training it\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(32,32,1)),\n",
        "    #tf.keras.Input(shape=(32, 32, 1))\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=1, \n",
        "        kernel_size=(5, 5), \n",
        "        padding='same', \n",
        "        activation='relu', \n",
        "        input_shape = (32,32,1)\n",
        "    ),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
        "    tf.keras.layers.Conv2D(1, (1,1), strides=1, activation=\"relu\"),\n",
        "    tf.keras.layers.UpSampling2D((2, 2), interpolation=\"bilinear\"),\n",
        "    tf.keras.layers.Conv2D(1, (1,1), strides=1, activation=\"relu\"),\n",
        "    tf.keras.layers.Flatten(input_shape=(32,32,1)),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(26, activation='relu')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "model.fit(\n",
        "    np.array(train_images), np.array(train_labels), epochs=5, batch_size = 500) \n",
        "np.array(train_labels)\n",
        "# model.fit(np.array(train_images), np.array(train_labels),batch_size=100, epochs=3, verbose=1, validation_data=(x_test, s_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 1)         26        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 1)         2         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 1)         2         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 26)                1690      \n",
            "=================================================================\n",
            "Total params: 1,748,600\n",
            "Trainable params: 1,748,600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "42/42 [==============================] - 14s 321ms/step - loss: 2.3470 - accuracy: 0.3735\n",
            "Epoch 2/5\n",
            "42/42 [==============================] - 13s 318ms/step - loss: 0.3896 - accuracy: 0.9028\n",
            "Epoch 3/5\n",
            "42/42 [==============================] - 13s 319ms/step - loss: 0.2243 - accuracy: 0.9403\n",
            "Epoch 4/5\n",
            "42/42 [==============================] - 13s 317ms/step - loss: 0.0796 - accuracy: 0.9798\n",
            "Epoch 5/5\n",
            "42/42 [==============================] - 13s 321ms/step - loss: 0.0465 - accuracy: 0.9876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  9,  6, ..., 25, 22, 17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxthpDLyAc7"
      },
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(32, (5, 5), strides = (1, 1), name = 'conv0', input_shape = (32, 32, 1)))\n",
        "\n",
        "# model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(MaxPooling2D((2, 2), name='max_pool'))\n",
        "# model.add(Conv2D(64, (3, 3), strides = (1,1), name=\"conv1\"))\n",
        "# model.add(Activation('relu'))\n",
        "# # model.add(AveragePooling2D((3, 3), name='avg_pool'))\n",
        "\n",
        "# # model.add(GlobalAveragePooling2D())\n",
        "# model.add(Dense(300, activation=\"relu\", name='rl'))\n",
        "# # model.add(Dropout(0.5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssiXMKcSyLcg"
      },
      "source": [
        "\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "# # model.fit(np.array(train_images), np.array(train_labels), epochs=10)\n",
        "# # model.fit(np.array(train_images), np.array(train_labels),batch_size=100, epochs=3, verbose=1, validation_data=(x_test, s_test))\n",
        "# batch_size = 32\n",
        "# nb_epoch = 500\n",
        "# # %%time\n",
        "# # Train model\n",
        "# history = model.fit(np.array(train_images), np.array(train_labels),batch_size=batch_size,epochs=nb_epoch, validation_split=0.2,shuffle=True,verbose=2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bg-eivq3gDe"
      },
      "source": [
        "# input_layer1 = Input((25, 67, 1))\n",
        "# print(input_layer1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icb22xMwKkg"
      },
      "source": [
        "# input_layer = image_size\n",
        "# # print(input_layer)\n",
        "# x = Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation='relu')(input_layer)\n",
        "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# x = Conv2D(filters=48, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# x = Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# x = Dropout(0.3)(x)\n",
        "# x = Flatten()(x)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "# x = Dropout(0.3)(x)\n",
        "\n",
        "# out = [Dense(10, name='digit%d' % i, activation='softmax')(x) for i in range(NUM_OF_LETTERS)]\n",
        "# model = Model(inputs=input_layer, outputs=out)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuejyM2BFbyp"
      },
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Conv2D(36, 3, activation='relu',\n",
        "#                            kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
        "#                            input_shape=(28, 28, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.1),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     tf.keras.layers.BatchNormalization(),\n",
        "#     tf.keras.layers.Dense(10)\n",
        "# ])\n",
        "\n",
        "# # Model is the full model w/o custom layers\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(np.array(train_images), epochs=3)\n",
        "# loss, acc = model.evaluate(test_data)\n",
        "# # , np.array(train_labels)\n",
        "# print(\"Loss {}, Accuracy {}\".format(loss, acc))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU_CdEtUFbnN"
      },
      "source": [
        "# def conv_block(inputs, filters, pool=True):\n",
        "#     x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "\n",
        "#     x = Conv2D(filters, 3, padding=\"same\")(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "\n",
        "#     if pool == True:\n",
        "#         p = MaxPool2D((2, 2))(x)\n",
        "#         return x, p\n",
        "#     else:\n",
        "#         return x\n",
        "\n",
        "# # def build_unet(shape, num_classes):\n",
        "# #     inputs = Input(shape)\n",
        "\n",
        "# #     \"\"\" Encoder \"\"\"\n",
        "# #     # x1, p1 = conv_block(inputs, 16, pool=True)\n",
        "# #     # x2, p2 = conv_block(p1, 32, pool=True)\n",
        "# #     # x3, p3 = conv_block(p2, 48, pool=True)\n",
        "# #     # x4, p4 = conv_block(p3, 64, pool=True)\n",
        "# #     x1, p1 = conv_block(inputs, 1, pool=True)\n",
        "# #     x2, p2 = conv_block(p1, 5, pool=True)\n",
        "# #     x3, p3 = conv_block(p2, 10, pool=True)\n",
        "# #     x4, p4 = conv_block(p3, 15, pool=True)\n",
        "\n",
        "# #     \"\"\" Bridge \"\"\"\n",
        "# #     # b1 = conv_block(p4, 128, pool=False)\n",
        "# #     b1 = conv_block(p4, 18, pool=False)\n",
        "\n",
        "# #     \"\"\" Decoder \"\"\"\n",
        "# #     u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
        "# #     c1 = Concatenate()([u1, x4])\n",
        "# #     x5 = conv_block(c1, 15, pool=False)\n",
        "\n",
        "# #     u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
        "# #     c2 = Concatenate()([u2, x3])\n",
        "# #     x6 = conv_block(c2, 10, pool=False)\n",
        "\n",
        "# #     u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
        "# #     c3 = Concatenate()([u3, x2])\n",
        "# #     x7 = conv_block(c3, 5, pool=False)\n",
        "\n",
        "# #     u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
        "# #     c4 = Concatenate()([u4, x1])\n",
        "# #     x8 = conv_block(c4, 1, pool=False)\n",
        "\n",
        "#     \"\"\" Output layer \"\"\"\n",
        "#     output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
        "\n",
        "#     return Model(inputs, output)\n",
        "\n",
        "# # # Model is the full model w/o custom layers\n",
        "# # model.compile(optimizer='adam',\n",
        "# #               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "# #               metrics=['accuracy'])\n",
        "\n",
        "# # model.fit(np.array(train_images), epochs=3)\n",
        "# # loss, acc = model.evaluate(test_data)\n",
        "# # # , np.array(train_labels)\n",
        "# # print(\"Loss {}, Accuracy {}\".format(loss, acc))\n",
        "# # model = build_unet((20, 20, 3), 26)\n",
        "# # model.summary()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db79yJnOzy7g"
      },
      "source": [
        "# system(\"mkdir -p models\")\n",
        "# model.save('./models/my_model_84.h5')\n",
        "\n",
        "# # Predicting on test images\n",
        "# probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "# predictions = probability_model.predict(np.array(test_images))\n",
        "\n",
        "# p=0\n",
        "# for i in range(len(test_images)):\n",
        "#   if np.argmax(predictions[i]) == test_labels[i]:\n",
        "#     p+=1\n",
        "\n",
        "# print(\"Test accuracy: \", 100*p/len(test_images))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bax_QAlMbajf"
      },
      "source": [
        "# !git clone https://github.com/captcha-breakers/ubiquitous-pancake.git"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKn6ChlkbcgD"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcEypgpaawjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "8e9c860c-d1d4-4476-e591-7f40c5d94bca"
      },
      "source": [
        "fil_dir = \"./D-captchas-simple-salt-n-pepper/data/\"\n",
        "total = 0\n",
        "char_p = 0\n",
        "char_n = 0\n",
        "cap_p = 0\n",
        "cap_n = 0\n",
        "\n",
        "for fil in listdir(fil_dir)[:1000]:\n",
        "  image = cv2.imread(fil_dir + fil)\n",
        "  # imshow(image), plt.show()\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
        "  _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  cnts, new = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] \n",
        "  captcha = np.invert(thresh)\n",
        "  labelled_captcha = measure.label(captcha)\n",
        "\n",
        "  character_dimensions = (\n",
        "      0.25*captcha.shape[0], \n",
        "      0.95*captcha.shape[0], \n",
        "      0.05*captcha.shape[1], \n",
        "      0.3*captcha.shape[1]\n",
        "  )\n",
        "  min_height, max_height, min_width, max_width = character_dimensions\n",
        "\n",
        "  characters = []\n",
        "  charactersx = []\n",
        "  counter=0\n",
        "  column_list = []\n",
        "  row_list = []\n",
        "  d = []\n",
        "  for regions in regionprops(labelled_captcha):\n",
        "      y0, x0, y1, x1 = regions.bbox\n",
        "      region_height = y1 - y0\n",
        "      region_width = x1 - x0\n",
        "\n",
        "      if region_height > min_height and region_height < max_height and region_width > min_width and region_width < max_width:\n",
        "          roi = captcha[y0:y1, x0:x1]\n",
        "          resized_char = cv2.copyMakeBorder(roi, 10, 10, 10, 10, cv2.BORDER_CONSTANT)\n",
        "          resized_char = resize(roi, image_size)\n",
        "          column_list.append(x0)\n",
        "          d.append([x0, resized_char])\n",
        "  d = sorted(d)\n",
        "  predicted_captcha = \"\"  \n",
        "  ind=0\n",
        "  result = []\n",
        "  probability_model = tf.keras.Sequential([model, tf.keras.layers.ReLU()])\n",
        "  #probability_model = tf.keras.Model(new_model, tf.keras.layers.ReLU())\n",
        "  #probability_model.summary()\n",
        "  for _,each_character in d:\n",
        "      x_p,y_p = 3,3\n",
        "      each_character = cv2.copyMakeBorder(each_character, x_p, x_p, y_p, y_p, cv2.BORDER_CONSTANT)\n",
        "      each_character = cv2.resize(each_character,image_size)\n",
        "\n",
        "      # imshow(each_character), plt.show()\n",
        "\n",
        "      each_character = np.expand_dims(each_character, axis=0)\n",
        "      each_character = np.expand_dims(each_character, axis=-1)\n",
        "     \n",
        "      result, = probability_model.predict([each_character])\n",
        "      \n",
        "      r = np.argmax(result)\n",
        "      # print(r, len(result))\n",
        "\n",
        "      if fil[ind] == chr(65+r):char_p += 1\n",
        "      else:char_n += 1\n",
        "      \n",
        "      predicted_captcha+=chr(65+r)\n",
        "\n",
        "      ind += 1\n",
        "  \n",
        "  if predicted_captcha == fil[:6]: cap_p+=1\n",
        "  else:cap_n+=1\n",
        "\n",
        "  # Statistics\n",
        "  stats = pd.DataFrame(\n",
        "    [\n",
        "        [char_p, char_n, 100*char_p/(char_p+char_n)], \n",
        "        [cap_p, cap_n, 100*cap_p/(cap_p+cap_n)]\n",
        "    ], \n",
        "    index=[\"Char\", \"Captcha\"],\n",
        "    columns=[\"Pos\", \"Neg\", \"Acc\"]\n",
        "  )\n",
        "  total+=1\n",
        "  clear_output(wait=True)\n",
        "  display(HTML(stats.to_html()))\n",
        "  print(\"Current file: \", total)\n",
        "  print(fil[:6], \":\", predicted_captcha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pos</th>\n",
              "      <th>Neg</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Char</th>\n",
              "      <td>1250</td>\n",
              "      <td>200</td>\n",
              "      <td>86.206897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Captcha</th>\n",
              "      <td>154</td>\n",
              "      <td>100</td>\n",
              "      <td>60.629921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}