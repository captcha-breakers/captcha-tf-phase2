{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Captcha-using-tensorflow-on-chars74K.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBaKsoPeoykt"
      },
      "source": [
        "# Developer docs\n",
        "# https://www.tensorflow.org/tutorials/keras/classification\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "\n",
        "# Importing modules\n",
        "from os import listdir, system\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import cv2 as cv2\n",
        "import imutils\n",
        "import imageio\n",
        "import pickle\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "import tensorflow as tf\n",
        "from skimage.io import imread\n",
        "from skimage import measure\n",
        "from skimage.measure import regionprops\n",
        "from skimage.transform import resize\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "# Downloading dataset from: http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
        "# You can comment this after running once.\n",
        "\n",
        "### CHARS74K DATASET FOR TRAINING\n",
        "# !wget http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
        "# !tar -xvzf ./EnglishImg.tgz && rm -rf EnglishImg.tgz\n",
        "# !git clone https://github.com/captcha-breakers/dataset-training-uppercase-1.git\n",
        "\n",
        "# CAPTCHA DATA: DOWNLOAD ANYONE & APPROPRIATELY CONFIGURE THE PATH\n",
        "# !git clone https://github.com/captcha-breakers/dataset-simple-uppercase.git\n",
        "# !git clone https://github.com/rdmpage/solving-captchas-code-examples.git\n",
        "# !git clone https://github.com/captcha-breakers/dataset-pycaptcha-uppercase.git"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IIDQCtPpAxe",
        "outputId": "3a83fcfd-5935-4f9b-87e2-a5a1660c9103"
      },
      "source": [
        "# Setting up folders\n",
        "base_dir = \"./dataset-training-uppercase-1/data/\"\n",
        "folders = listdir(base_dir)\n",
        "folders.sort()\n",
        "folders = folders[:36]\n",
        "print(folders)\n",
        "\n",
        "# Setting image_size\n",
        "image_size = (20, 20)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sample1', 'Sample10', 'Sample11', 'Sample12', 'Sample13', 'Sample14', 'Sample15', 'Sample16', 'Sample17', 'Sample18', 'Sample19', 'Sample2', 'Sample20', 'Sample21', 'Sample22', 'Sample23', 'Sample24', 'Sample25', 'Sample26', 'Sample27', 'Sample28', 'Sample29', 'Sample3', 'Sample30', 'Sample31', 'Sample32', 'Sample33', 'Sample34', 'Sample35', 'Sample36', 'Sample4', 'Sample5', 'Sample6', 'Sample7', 'Sample8', 'Sample9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnjsqbFbpFOQ",
        "outputId": "6e5d4a9f-54f2-48a4-cfe2-453434596964"
      },
      "source": [
        "# Collecting images from folders\n",
        "data = []\n",
        "total_images = 0\n",
        "for i in folders:\n",
        "    all_images = listdir(base_dir+i)[:1000]\n",
        "    total_images+=len(all_images)\n",
        "    currentlabel = int(i[6:])-1\n",
        "\n",
        "    for name in all_images:\n",
        "        image = cv2.imread(base_dir+i+\"/\"+name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = cv2.resize(image, image_size)\n",
        "\n",
        "        # Filtering\n",
        "        # image = cv2.GaussianBlur(image,(5,5),0)\n",
        "        # image = cv2.Laplacian(image,cv2.CV_64F)\n",
        "        # image = cv2.GaussianBlur(image,(5,5),0)\n",
        "        # kernel = np.ones((3, 3), np.uint8)\n",
        "        # image = cv2.filter2D(image,-1,kernel)\n",
        "        \n",
        "        data.append((image/255, currentlabel))\n",
        "    \n",
        "    if int(i[6:])<=10:\n",
        "      print(\"Images for\", currentlabel,\":\",  len(all_images))\n",
        "    else:\n",
        "      print(\"Images for\", chr(65-11+currentlabel+1),\":\",  len(all_images))\n",
        "print(\"Total images: \", total_images)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images for 0 : 1000\n",
            "Images for 9 : 1000\n",
            "Images for A : 1000\n",
            "Images for B : 1000\n",
            "Images for C : 1000\n",
            "Images for D : 1000\n",
            "Images for E : 1000\n",
            "Images for F : 1000\n",
            "Images for G : 1000\n",
            "Images for H : 1000\n",
            "Images for I : 1000\n",
            "Images for 1 : 1000\n",
            "Images for J : 1000\n",
            "Images for K : 1000\n",
            "Images for L : 1000\n",
            "Images for M : 1000\n",
            "Images for N : 1000\n",
            "Images for O : 1000\n",
            "Images for P : 1000\n",
            "Images for Q : 1000\n",
            "Images for R : 1000\n",
            "Images for S : 1000\n",
            "Images for 2 : 1000\n",
            "Images for T : 1000\n",
            "Images for U : 1000\n",
            "Images for V : 1000\n",
            "Images for W : 1000\n",
            "Images for X : 1000\n",
            "Images for Y : 1000\n",
            "Images for Z : 1000\n",
            "Images for 3 : 1000\n",
            "Images for 4 : 1000\n",
            "Images for 5 : 1000\n",
            "Images for 6 : 1000\n",
            "Images for 7 : 1000\n",
            "Images for 8 : 1000\n",
            "Total images:  36000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBEvr3VRpKLz"
      },
      "source": [
        "# Shuffling data & making train/test\n",
        "np.random.shuffle(data)\n",
        "n = len(data)\n",
        "p = int(80*n/100)\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(n):\n",
        "    if i<p:\n",
        "        train_images.append(data[i][0])\n",
        "        train_labels.append(data[i][1])\n",
        "    else:\n",
        "        test_images.append(data[i][0])\n",
        "        test_labels.append(data[i][1])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "OuF0sxtOMEwn",
        "outputId": "f039be59-dc79-402e-8b49-f9d6ab4d19bb"
      },
      "source": [
        "# Visualizing Training data\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "for i in range(10):\n",
        "  fig.add_subplot(2, 5, i+1)\n",
        "  print(data[i][1])\n",
        "  imshow(data[i][0])\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "27\n",
            "2\n",
            "16\n",
            "29\n",
            "30\n",
            "29\n",
            "30\n",
            "2\n",
            "23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yws9xKLpNHf",
        "outputId": "048a15e2-a5f5-4e44-eea0-a7e8d58a2fff"
      },
      "source": [
        "# Making the model and training it\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=image_size),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dense(36)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    np.array(train_images), \n",
        "    np.array(train_labels), \n",
        "    epochs=10,\n",
        "    batch_size=100\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.8006 - accuracy: 0.8419\n",
            "Epoch 2/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 3/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 3.1162e-04 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.2110e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 6.5978e-05 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 3.9203e-05 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 2.7566e-05 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.9746e-05 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "288/288 [==============================] - 2s 6ms/step - loss: 1.4247e-05 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "288/288 [==============================] - 2s 5ms/step - loss: 1.0484e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f659300dd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db79yJnOzy7g",
        "outputId": "e1d2fe5b-2c4b-434c-c467-1ea013ff90e7"
      },
      "source": [
        "system(\"mkdir -p models\")\n",
        "# model.save('./models/my_model_84.h5')\n",
        "\n",
        "# Predicting on test images\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(np.array(test_images))\n",
        "\n",
        "p=0\n",
        "for i in range(len(test_images)):\n",
        "  if np.argmax(predictions[i]) == test_labels[i]:\n",
        "    p+=1\n",
        "\n",
        "print(\"Test accuracy: \", 100*p/len(test_images))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:  100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "DcEypgpaawjr",
        "outputId": "d2ef12c0-452c-4c77-cd0b-69790c6d6511"
      },
      "source": [
        "fil_dir = \"./dataset-simple-uppercase/data/\"\n",
        "total = 0\n",
        "char_p = 0\n",
        "char_n = 0\n",
        "cap_p = 0\n",
        "cap_n = 0\n",
        "\n",
        "for fil in listdir(fil_dir)[:1000]:\n",
        "  image = cv2.imread(fil_dir + fil)\n",
        "  # imshow(image), plt.show()\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
        "  _, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  cnts, new = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] \n",
        "  captcha = np.invert(thresh)\n",
        "  labelled_captcha = measure.label(captcha)\n",
        "\n",
        "  character_dimensions = (\n",
        "      0.25*captcha.shape[0], \n",
        "      0.95*captcha.shape[0], \n",
        "      0.05*captcha.shape[1], \n",
        "      0.3*captcha.shape[1]\n",
        "  )\n",
        "  min_height, max_height, min_width, max_width = character_dimensions\n",
        "\n",
        "  characters = []\n",
        "  charactersx = []\n",
        "  counter=0\n",
        "  column_list = []\n",
        "  row_list = []\n",
        "  d = []\n",
        "  for regions in regionprops(labelled_captcha):\n",
        "      y0, x0, y1, x1 = regions.bbox\n",
        "      region_height = y1 - y0\n",
        "      region_width = x1 - x0\n",
        "\n",
        "      if region_height > min_height and region_height < max_height and region_width > min_width and region_width < max_width:\n",
        "          roi = captcha[y0:y1, x0:x1]\n",
        "          resized_char = cv2.copyMakeBorder(roi, 10, 10, 10, 10, cv2.BORDER_CONSTANT)\n",
        "          resized_char = resize(roi, image_size)\n",
        "          column_list.append(x0)\n",
        "          d.append([x0, resized_char])\n",
        "  d = sorted(d)\n",
        "  predicted_captcha = \"\"  \n",
        "  ind=0\n",
        "  for _,each_character in d:\n",
        "      x_p,y_p = 3,3\n",
        "      each_character = cv2.copyMakeBorder(each_character, x_p, x_p, y_p, y_p, cv2.BORDER_CONSTANT)\n",
        "      each_character = cv2.resize(each_character,image_size)\n",
        "      \n",
        "      # imshow(each_character), plt.show()\n",
        "      each_character = each_character.reshape(1, -1)\n",
        "    \n",
        "      result, = probability_model.predict([each_character])\n",
        "      r = np.argmax(result)\n",
        "      \n",
        "      if r<10:\n",
        "        # print(chr(48+r))\n",
        "        predicted_captcha+=chr(48+r)\n",
        "        if fil[ind] == chr(48+r):char_p += 1\n",
        "        else:char_n += 1\n",
        "      else:\n",
        "        # print(chr(55+r))\n",
        "        predicted_captcha+=chr(65-10+r)\n",
        "        if fil[ind] == chr(65-10+r):char_p += 1\n",
        "        else:char_n += 1\n",
        "      ind += 1\n",
        "  \n",
        "  if predicted_captcha == fil[:6]: cap_p+=1\n",
        "  else:cap_n+=1\n",
        "\n",
        "  # Statistics\n",
        "  stats = pd.DataFrame(\n",
        "    [\n",
        "        [char_p, char_n, 100*char_p/(char_p+char_n)], \n",
        "        [cap_p, cap_n, 100*cap_p/(cap_p+cap_n)]\n",
        "    ], \n",
        "    index=[\"Char\", \"Captcha\"],\n",
        "    columns=[\"Pos\", \"Neg\", \"Acc\"]\n",
        "  )\n",
        "  total+=1\n",
        "  clear_output(wait=True)\n",
        "  display(HTML(stats.to_html()))\n",
        "  print(\"Current file: \", total)\n",
        "  print(fil[:6], \":\", predicted_captcha)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pos</th>\n",
              "      <th>Neg</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Char</th>\n",
              "      <td>4882</td>\n",
              "      <td>833</td>\n",
              "      <td>85.424322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Captcha</th>\n",
              "      <td>592</td>\n",
              "      <td>408</td>\n",
              "      <td>59.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current file:  1000\n",
            "LWXPKE : LKPKE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}